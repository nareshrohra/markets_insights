{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pwd = os.path.abspath('.')\n",
    "os.chdir(os.path.join(pwd, '../src/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Get Index data for date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markets_insights.datareader import data_reader\n",
    "import datetime\n",
    "\n",
    "reader = data_reader.NseIndicesReader()\n",
    "\n",
    "daterange_reader = data_reader.DateRangeDataReader(reader)\n",
    "\n",
    "from_date = datetime.date(2023, 1, 1)\n",
    "to_date = datetime.date(2023, 12, 31)\n",
    "result = daterange_reader.read(from_date = from_date, to_date = to_date)\n",
    "print(result.head(5).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get daily, monthly and annually aggregrated data\n",
    "In this example we will use HistoricalDataProcessor class to get data between a date range. HistoricalDataProcessor will also do monthly and annual aggregation of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started to read data\n",
      "HistoricalDataProcessor.get_data took 0 seconds\n",
      "HistoricalDataProcessor.get_manual_data took 0 seconds\n",
      "HistoricalDataProcessor.run_base_calculations took 1 seconds\n",
      "Started periodic calculation for Month\n",
      "HistoricalDataProcessor.add_monthly_growth_calc took 0 seconds\n",
      "Started periodic calculation for Year\n",
      "HistoricalDataProcessor.add_yearly_growth_calc took 0 seconds\n",
      "HistoricalDataProcessor.process took 2 seconds\n"
     ]
    }
   ],
   "source": [
    "# import classes & setup\n",
    "from markets_insights.dataprocess.data_processor import HistoricalDataProcessor\n",
    "from markets_insights.datareader.data_reader import NseIndicesReader\n",
    "histDataProcessor = HistoricalDataProcessor()\n",
    "\n",
    "# Fetch and process the data\n",
    "year_start = datetime.date(2023, 1, 1)\n",
    "year_end = datetime.date(2023, 12, 31)\n",
    "result = histDataProcessor.process(NseIndicesReader(), {'from_date': year_start, 'to_date': year_end})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      | Identifier                                  | Date                | Month   |      Volume |    Turnover |    Close |     High |        Low |       Open |\n",
      "|-----:|:--------------------------------------------|:--------------------|:--------|------------:|------------:|---------:|---------:|-----------:|-----------:|\n",
      "|    0 | INDIA VIX                                   | 2023-01-31 00:00:00 | 2023-01 | 0           | 0           |    16.88 |    19.39 |    11.6425 |    14.8675 |\n",
      "| 1012 | NIFTY100 ENHANCED ESG                       | 2023-01-31 00:00:00 | 2023-01 | 8.12952e+09 | 4.99243e+12 |  3352.6  |  3490.75 |  3352.6    |  3472.29   |\n",
      "|  228 | NIFTY ALPHA QUALITY VALUE LOW-VOLATILITY 30 | 2023-01-31 00:00:00 | 2023-01 | 2.32482e+09 | 1.3303e+12  | 11286.1  | 11599.4  | 11214.5    | 11456.8    |\n"
     ]
    }
   ],
   "source": [
    "from markets_insights.core.column_definition import BaseColumns\n",
    "\n",
    "print(result.get_monthly_data().sort_values(BaseColumns.Date).head(3).to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation pipeline for RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started to read data\n",
      "HistoricalDataProcessor.get_data took 1 seconds\n",
      "HistoricalDataProcessor.get_manual_data took 0 seconds\n",
      "HistoricalDataProcessor.run_base_calculations took 18 seconds\n",
      "HistoricalDataProcessor.process took 19 seconds\n",
      "RsiCalculationWorker took 9 seconds\n",
      "ValueCrossedAboveFlagWorker took 1 seconds\n",
      "ValueCrossedBelowFlagWorker took 1 seconds\n"
     ]
    }
   ],
   "source": [
    "# import classes & setup options\n",
    "import datetime\n",
    "from markets_insights.datareader.data_reader import BhavCopyReader\n",
    "from markets_insights.dataprocess.data_processor import HistoricalDataProcessor, MultiDataCalculationPipelines, CalculationPipelineBuilder, HistoricalDataProcessOptions\n",
    "from markets_insights.calculations.base import DatePartsCalculationWorker\n",
    "\n",
    "reader = BhavCopyReader()\n",
    "options = HistoricalDataProcessOptions()\n",
    "options.include_monthly_data = False\n",
    "options.include_annual_data = False\n",
    "histDataProcessor = HistoricalDataProcessor(options)\n",
    "\n",
    "# Fetch the data\n",
    "year_start = datetime.date(2023, 1, 1)\n",
    "to_date = datetime.date(2023, 12, 31)\n",
    "result = histDataProcessor.process(reader, {'from_date': year_start, 'to_date': to_date})\n",
    "\n",
    "# Prepare calculation pipeline\n",
    "pipelines = MultiDataCalculationPipelines()\n",
    "pipelines.set_item('rsi', CalculationPipelineBuilder.create_rsi_calculation_pipeline())\n",
    "histDataProcessor.set_calculation_pipelines(pipelines)\n",
    "\n",
    "# Run the pipeline\n",
    "histDataProcessor.run_calculation_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|        | Identifier   | Date                |   Close |     Rsi |\n",
      "|-------:|:-------------|:--------------------|--------:|--------:|\n",
      "| 336063 | RKFORGE      | 2023-12-29 00:00:00 |  725.7  | 46.9257 |\n",
      "| 329710 | RBL          | 2023-12-29 00:00:00 |  852.95 | 54.8479 |\n",
      "| 446931 | ZYDUSWELL    | 2023-12-29 00:00:00 | 1681.1  | 72.0492 |\n"
     ]
    }
   ],
   "source": [
    "from markets_insights.core.column_definition import BaseColumns, CalculatedColumns\n",
    "\n",
    "print(result.get_daily_data().sort_values(BaseColumns.Date).tail(3)[[BaseColumns.Identifier, BaseColumns.Date, BaseColumns.Close, CalculatedColumns.RelativeStrengthIndex]].to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A real use case: Understand the affect of RSI and Stochastic RSI on price\n",
    "In this use case, understand the affect of RSI and Stochastic RSI on price\n",
    "\n",
    "##Preparing the data\n",
    "Calculate RSI and Stochastic RSI for each day.\n",
    "Add a flag for whenever the RSI crosses the control limits (eg: above 75 and below 30)\n",
    "Calculate the highest and lowest price change in the next 10 trading sessions.\n",
    "\n",
    "##Analyse\n",
    "We will find the average for highest price change and lowest price change whenever the RSI crosses the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started to read data\n",
      "HistoricalDataProcessor.get_data took 1 seconds\n",
      "HistoricalDataProcessor.get_manual_data took 0 seconds\n",
      "HistoricalDataProcessor.run_base_calculations took 17 seconds\n",
      "HistoricalDataProcessor.process took 18 seconds\n"
     ]
    }
   ],
   "source": [
    "# import classes\n",
    "from markets_insights.datareader.data_reader import BhavCopyReader\n",
    "\n",
    "# Fetch the data\n",
    "year_start = datetime.date(2023, 1, 1)\n",
    "to_date = datetime.date(2023, 12, 31)\n",
    "result = histDataProcessor.process(BhavCopyReader(), {'from_date': year_start, 'to_date': to_date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RsiCalculationWorker took 9 seconds\n",
      "ValueCrossedAboveFlagWorker took 1 seconds\n",
      "ValueCrossedBelowFlagWorker took 1 seconds\n",
      "StochRsiCalculationWorker took 13 seconds\n",
      "ValueCrossedAboveFlagWorker took 1 seconds\n",
      "ValueCrossedAboveFlagWorker took 1 seconds\n",
      "ValueCrossedBelowFlagWorker took 1 seconds\n",
      "ValueCrossedBelowFlagWorker took 1 seconds\n",
      "LowestPriceInNextNDaysCalculationWorker took 1 seconds\n",
      "LowestPriceInNextNDaysCalculationWorker took 1 seconds\n",
      "LowestPriceInNextNDaysCalculationWorker took 1 seconds\n",
      "LowestPriceInNextNDaysCalculationWorker took 1 seconds\n",
      "LowestPriceInNextNDaysCalculationWorker took 1 seconds\n",
      "HighestPriceInNextNDaysCalculationWorker took 1 seconds\n",
      "HighestPriceInNextNDaysCalculationWorker took 1 seconds\n",
      "HighestPriceInNextNDaysCalculationWorker took 1 seconds\n",
      "HighestPriceInNextNDaysCalculationWorker took 1 seconds\n",
      "HighestPriceInNextNDaysCalculationWorker took 1 seconds\n"
     ]
    }
   ],
   "source": [
    "# prepare calculation pipeline\n",
    "periods = [1, 7, 15, 30, 45]\n",
    "\n",
    "pipelines = MultiDataCalculationPipelines()\n",
    "pipelines.set_item('rsi', CalculationPipelineBuilder.create_rsi_calculation_pipeline(crossing_above_flag_value = 75, crossing_below_flag_value = 30, window = 14))\n",
    "pipelines.set_item('stoch_rsi', CalculationPipelineBuilder.create_stoch_rsi_calculation_pipeline(crossing_above_flag_value = 80, crossing_below_flag_value = 20, window = 14))\n",
    "pipelines.set_item('foward_looking_fall', CalculationPipelineBuilder.create_forward_looking_price_fall_pipeline(periods))\n",
    "pipelines.set_item('foward_looking_rise', CalculationPipelineBuilder.create_forward_looking_price_rise_pipeline(periods))\n",
    "histDataProcessor.set_calculation_pipelines(pipelines=pipelines)\n",
    "\n",
    "# run the pipeline and show results\n",
    "histDataProcessor.run_calculation_pipelines()\n",
    "\n",
    "daily_data = result.get_daily_data()\n",
    "\n",
    "# Import constants so its easier to refer to column names\n",
    "from markets_insights.core.column_definition import BaseColumns, CalculatedColumns\n",
    "\n",
    "# get names of fwd looking price column names. Since, these column names are auto-generated there no constants for them\n",
    "fwd_looking_price_fall_cols, fwd_looking_price_rise_cols = [x for x in daily_data.columns if 'HighestPercFallInNext' in x], \\\n",
    "    [x for x in daily_data.columns if 'HighestPercRiseInNext' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighestPercFallInNext1Days     1.418923\n",
       "HighestPercFallInNext7Days     3.771446\n",
       "HighestPercFallInNext15Days    4.777241\n",
       "HighestPercFallInNext30Days    6.055861\n",
       "HighestPercFallInNext45Days    6.785467\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyse the median price change % for highest price fall whenever the RSI crosses above\n",
    "daily_data[\n",
    "  (daily_data[CalculatedColumns.RsiCrossedAbove])\n",
    "][fwd_looking_price_fall_cols].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighestPercRiseInNext1Days      3.875000\n",
       "HighestPercRiseInNext7Days      7.589087\n",
       "HighestPercRiseInNext15Days     9.756772\n",
       "HighestPercRiseInNext30Days    13.255317\n",
       "HighestPercRiseInNext45Days    16.292135\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyse the median price change % for highest price rise whenever the RSI crosses below\n",
    "daily_data[\n",
    "  (daily_data[CalculatedColumns.RsiCrossedBelow] == True)\n",
    "][fwd_looking_price_rise_cols].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended Data Reader for Nasdaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas\n",
    "from markets_insights.datareader.data_reader import DateRangeDataReader\n",
    "from markets_insights.core.core import Instrumentation\n",
    "from markets_insights.core.column_definition import BaseColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NasdaqDataReader (DateRangeDataReader):\n",
    "  def __init__(self, tickers: list = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META', 'TSLA', 'NVDA']):\n",
    "    super().__init__(reader=None)\n",
    "    self.tickers = tickers\n",
    "    self.name = \"NasdaqDataReader\"\n",
    "\n",
    "  @Instrumentation.trace(name=\"NasdaqDataReader.read\")\n",
    "  def read(self, from_date, to_date):\n",
    "    df_list = list()\n",
    "    for ticker in self.tickers:\n",
    "        data = yf.download(ticker, group_by=\"Ticker\", start=from_date, end=to_date)\n",
    "        data['ticker'] = ticker\n",
    "        df_list.append(data)\n",
    "\n",
    "    # combine all dataframes into a single dataframe\n",
    "    df = pandas.concat(df_list)\n",
    "\n",
    "    final_data = df.reset_index().rename(columns = self.get_column_name_mappings())\n",
    "    final_data[BaseColumns.Date] = pandas.to_datetime(final_data[BaseColumns.Date])\n",
    "    return final_data\n",
    "  \n",
    "  def get_column_name_mappings(self):\n",
    "    return {\n",
    "      'ticker': BaseColumns.Identifier,\n",
    "      'OPEN': BaseColumns.Open,\n",
    "      'HIGH': BaseColumns.High,\n",
    "      'LOW': BaseColumns.Low,\n",
    "      'CLOSE': BaseColumns.Close\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NasdaqDataReader.read took 2 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>2023-12-22</td>\n",
       "      <td>491.950012</td>\n",
       "      <td>493.829987</td>\n",
       "      <td>484.670013</td>\n",
       "      <td>488.299988</td>\n",
       "      <td>488.299988</td>\n",
       "      <td>25213900</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>489.679993</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>489.600006</td>\n",
       "      <td>492.790009</td>\n",
       "      <td>492.790009</td>\n",
       "      <td>24420000</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>495.109985</td>\n",
       "      <td>496.799988</td>\n",
       "      <td>490.850006</td>\n",
       "      <td>494.170013</td>\n",
       "      <td>494.170013</td>\n",
       "      <td>23364800</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>496.429993</td>\n",
       "      <td>498.839996</td>\n",
       "      <td>494.119995</td>\n",
       "      <td>495.220001</td>\n",
       "      <td>495.220001</td>\n",
       "      <td>24658700</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>498.130005</td>\n",
       "      <td>499.970001</td>\n",
       "      <td>487.510010</td>\n",
       "      <td>495.220001</td>\n",
       "      <td>495.220001</td>\n",
       "      <td>38869000</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "1745 2023-12-22  491.950012  493.829987  484.670013  488.299988  488.299988   \n",
       "1746 2023-12-26  489.679993  496.000000  489.600006  492.790009  492.790009   \n",
       "1747 2023-12-27  495.109985  496.799988  490.850006  494.170013  494.170013   \n",
       "1748 2023-12-28  496.429993  498.839996  494.119995  495.220001  495.220001   \n",
       "1749 2023-12-29  498.130005  499.970001  487.510010  495.220001  495.220001   \n",
       "\n",
       "        Volume Identifier  \n",
       "1745  25213900       NVDA  \n",
       "1746  24420000       NVDA  \n",
       "1747  23364800       NVDA  \n",
       "1748  24658700       NVDA  \n",
       "1749  38869000       NVDA  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_start = datetime.date(2023, 1, 1)\n",
    "to_date = datetime.date(2023, 12, 31)\n",
    "NasdaqDataReader().read(from_date=year_start, to_date=to_date).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started to read data\n",
      "Reading data from 2023-01-02 to 2023-12-29\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "NasdaqDataReader.read took 3 seconds\n",
      "Saving data to file: ../../_data/processed/historical/NasdaqDataReader.csv\n",
      "get_data took 3 seconds\n",
      "get_manual_data took 0 seconds\n",
      "Started basic calculation\n",
      "add_basic_calc took 0 seconds\n",
      "process took 3 seconds\n",
      "DatePartsCalculationWorker took 0 seconds\n",
      "RsiCalculationWorker took 0 seconds\n",
      "ValueCrossedAboveFlagWorker took 0 seconds\n",
      "ValueCrossedBelowFlagWorker took 0 seconds\n"
     ]
    }
   ],
   "source": [
    "# import classes & setup options\n",
    "import datetime\n",
    "from markets_insights.dataprocess.data_processor import HistoricalDataProcessor, MultiDataCalculationPipelines, CalculationPipelineBuilder, HistoricalDataProcessOptions\n",
    "from markets_insights.calculations.base import DatePartsCalculationWorker\n",
    "\n",
    "reader = NasdaqDataReader()\n",
    "options = HistoricalDataProcessOptions()\n",
    "options.include_monthly_data = False\n",
    "options.include_annual_data = False\n",
    "histDataProcessor = HistoricalDataProcessor(options)\n",
    "\n",
    "# Fetch the data\n",
    "year_start = datetime.date(2023, 1, 1)\n",
    "to_date = datetime.date(2023, 12, 31)\n",
    "result = histDataProcessor.process(reader, {'from_date': year_start, 'to_date': to_date})\n",
    "\n",
    "# Prepare calculation pipeline\n",
    "pipelines = MultiDataCalculationPipelines()\n",
    "pipelines.set_item('date_parts', CalculationPipelineBuilder.create_pipeline_for_worker(DatePartsCalculationWorker()))\n",
    "pipelines.set_item('rsi', CalculationPipelineBuilder.create_rsi_calculation_pipeline())\n",
    "histDataProcessor.set_calculation_pipelines(pipelines)\n",
    "\n",
    "# Run the pipeline\n",
    "histDataProcessor.run_calculation_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PreviousClose', 'Turnover (Rs. Cr.)', 'TOTTRDQTY'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmarkets_insights\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TypeHelper\n\u001b[1;32m----> 2\u001b[0m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_daily_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTypeHelper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_class_static_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBaseColumns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\NRohra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\NRohra\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\NRohra\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['PreviousClose', 'Turnover (Rs. Cr.)', 'TOTTRDQTY'] not in index\""
     ]
    }
   ],
   "source": [
    "from markets_insights.core.core import TypeHelper\n",
    "result.get_daily_data()[TypeHelper.get_class_static_values(BaseColumns)].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|      | Identifier   | Date                |   Close |     Rsi |\\n|-----:|:-------------|:--------------------|--------:|--------:|\\n|  248 | AAPL         | 2023-12-28 00:00:00 |  193.58 | 54.4815 |\\n|  497 | AMZN         | 2023-12-28 00:00:00 |  153.38 | 63.9387 |\\n|  746 | GOOGL        | 2023-12-28 00:00:00 |  140.23 | 61.585  |\\n|  995 | META         | 2023-12-28 00:00:00 |  358.32 | 70.2377 |\\n| 1244 | MSFT         | 2023-12-28 00:00:00 |  375.28 | 56.909  |\\n| 1493 | NVDA         | 2023-12-28 00:00:00 |  495.22 | 58.305  |\\n| 1742 | TSLA         | 2023-12-28 00:00:00 |  253.18 | 55.9788 |'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from markets_insights.core.column_definition import CalculatedColumns\n",
    "\n",
    "result.get_daily_data() \\\n",
    "  .sort_values(\n",
    "    [BaseColumns.Date, BaseColumns.Identifier]\n",
    "  )[\n",
    "    [BaseColumns.Identifier, BaseColumns.Date, BaseColumns.Close, \n",
    "     CalculatedColumns.RelativeStrengthIndex]\n",
    "  ] \\\n",
    "  .tail(7).to_markdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Calculation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markets_insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import modules\n",
    "from markets_insights.calculations.base import CalculationWorker\n",
    "from markets_insights.core.core import Instrumentation\n",
    "from markets_insights.calculations.base import BaseColumns\n",
    "import pandas\n",
    "\n",
    "# Implement the worker class. The important aspect here is to override the add_calculated_columns() method\n",
    "class FibonacciRetracementCalculationWorker (CalculationWorker):\n",
    "  def __init__(self, time_window: int, level_perct: float):\n",
    "    self._time_window = time_window\n",
    "    self._level = level_perct / 100\n",
    "    self._column_name = 'Fbr' + str(level_perct)\n",
    "\n",
    "  @Instrumentation.trace(name=\"FibnocciRetracementCalculationWorker\")\n",
    "  def add_calculated_columns(self, data: pandas.DataFrame):\n",
    "    identifier_grouped_data: pandas.DataFrame = data.groupby(BaseColumns.Identifier)\n",
    "    #Since, our dataframe may contain data for multiple symbols, we need to first group them by Identifier\n",
    "    data[self._column_name] = identifier_grouped_data[BaseColumns.Close].transform(\n",
    "        lambda x: \n",
    "          x.rolling(self._time_window).max() - \n",
    "          (\n",
    "            (x.rolling(self._time_window).max() - x.rolling(self._time_window).min())  * self._level\n",
    "          )\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started to read data\n",
      "HistoricalDataProcessor.get_data took 0 seconds\n",
      "HistoricalDataProcessor.get_manual_data took 0 seconds\n",
      "HistoricalDataProcessor.run_base_calculations took 0 seconds\n",
      "HistoricalDataProcessor.process took 0 seconds\n",
      "FibnocciRetracementCalculationWorker took 0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create pipline with the FibnocciRetracementCalculationWorker and run \n",
    "from markets_insights.datareader.data_reader import NseIndicesReader\n",
    "from markets_insights.dataprocess.data_processor import HistoricalDataProcessor, HistoricalDataProcessOptions, \\\n",
    "  MultiDataCalculationPipelines, CalculationPipeline\n",
    "histDataProcessor = HistoricalDataProcessor(HistoricalDataProcessOptions(include_monthly_data=False, include_annual_data=False))\n",
    "\n",
    "# Fetch the data\n",
    "result = histDataProcessor.process(NseIndicesReader(), {'from_date': datetime.date(2023, 12, 1), 'to_date': datetime.date(2023, 12, 31)})\n",
    "\n",
    "# Prepare calculation pipeline\n",
    "fbr50_worker = FibonacciRetracementCalculationWorker(time_window=7, level_perct=50)\n",
    "pipelines = MultiDataCalculationPipelines()\n",
    "histDataProcessor.set_calculation_pipelines(\n",
    "  CalculationPipeline(\n",
    "    workers = [fbr50_worker]\n",
    "  )\n",
    ")\n",
    "\n",
    "# Run the pipeline and get data\n",
    "histDataProcessor.run_calculation_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      | Identifier                    | Date                |    Close |    Fbr50 |\n",
      "|-----:|:------------------------------|:--------------------|---------:|---------:|\n",
      "| 2141 | NIFTY COMPOSITE G-SEC INDEX   | 2023-12-29 00:00:00 |  2602.3  |  2599.48 |\n",
      "| 2142 | NIFTY 10 YR BENCHMARK G-SEC   | 2023-12-29 00:00:00 |  2232.79 |  2230.24 |\n",
      "| 2143 | NIFTY MIDCAP SELECT           | 2023-12-29 00:00:00 | 10397.5  | 10209.1  |\n",
      "| 2144 | NIFTY ALPHA LOW-VOLATILITY 30 | 2023-12-29 00:00:00 | 23373.2  | 22886    |\n",
      "| 2145 | NIFTY50 USD                   | 2023-12-29 00:00:00 |  9048.9  |  8941.77 |\n"
     ]
    }
   ],
   "source": [
    "## Display the results\n",
    "print(result.get_daily_data()[[\n",
    "  BaseColumns.Identifier, BaseColumns.Date, BaseColumns.Close, fbr50_worker._column_name\n",
    "]].tail(5).to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
